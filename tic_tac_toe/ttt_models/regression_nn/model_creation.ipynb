{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input: Position Model: MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "      <th>String</th>\n",
       "      <th>Value</th>\n",
       "      <th>Remoteness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>---------</td>\n",
       "      <td>Tie</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>x--------</td>\n",
       "      <td>Tie</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>xo-------</td>\n",
       "      <td>Win</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>-x-------</td>\n",
       "      <td>Tie</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>ox-------</td>\n",
       "      <td>Tie</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Position     String Value  Remoteness\n",
       "0         0  ---------   Tie           9\n",
       "1         2  x--------   Tie           8\n",
       "2         5  xo-------   Win           5\n",
       "3         6  -x-------   Tie           8\n",
       "4         7  ox-------   Tie           7"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('tictactoe.csv',header=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "      <th>String</th>\n",
       "      <th>Value</th>\n",
       "      <th>Remoteness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[2, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>[2, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>[0, 2, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>[1, 2, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Position                       String  Value  Remoteness\n",
       "0         0  [0, 0, 0, 0, 0, 0, 0, 0, 0]      2           9\n",
       "1         2  [2, 0, 0, 0, 0, 0, 0, 0, 0]      2           8\n",
       "2         5  [2, 1, 0, 0, 0, 0, 0, 0, 0]      0           5\n",
       "3         6  [0, 2, 0, 0, 0, 0, 0, 0, 0]      2           8\n",
       "4         7  [1, 2, 0, 0, 0, 0, 0, 0, 0]      2           7"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0,1,2: win,lose,tie; 0:_; 1:o; 2:x\n",
    "# replace the data for training\n",
    "data=data.replace('Win',0)\n",
    "data=data.replace('Lose',1)\n",
    "data=data.replace('Tie',2)\n",
    "char_mapping = {'x': 2, 'o': 1, '-': 0}\n",
    "data['String'] = data['String'].apply(lambda s: [char_mapping[c] for c in s])\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash_table={}\n",
    "for idx,i in enumerate(data['String']):\n",
    "    hash_table[tuple(i)]=data['Position'][idx]\n",
    "hash_table[((0, 0, 0, 0, 0, 0, 0, 0, 0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=(data.iloc[0]['Value'],data.iloc[0]['Remoteness'])\n",
    "a=torch.tensor(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader,random_split\n",
    "\n",
    "class tttDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data.iloc[idx]\n",
    "        features = sample['String']  # 根据你的数据结构来处理特征和标签\n",
    "        value_label = sample['Value']\n",
    "        remoteness_label = sample['Remoteness']\n",
    "        return torch.tensor(features,dtype=torch.float32), torch.tensor(value_label,dtype=torch.long), torch.tensor(remoteness_label,dtype=torch.long)\n",
    "        # return torch.tensor(features,dtype=torch.float32) ,torch.tensor(label,dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tttDataset(data)\n",
    "# train_num=int(len(dataset)*0.8)\n",
    "# test_num=len(dataset)-train_num\n",
    "# train_dataset,test_dataset=random_split(dataset,[train_num,test_num])\n",
    "batch_size = 8\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "dataset_loader=DataLoader(dataset,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP,self).__init__()\n",
    "        self.flatten=nn.Flatten()\n",
    "        self.linear_relu_val = nn.Sequential(\n",
    "            nn.Linear(9,32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,64),\n",
    "            nn.ReLU(),\n",
    "            # nn.Linear(128,32),\n",
    "            # nn.ReLU(),\n",
    "            nn.Linear(64,3),\n",
    "            )\n",
    "        # ?\n",
    "        self.linear_relu_rem = nn.Sequential(\n",
    "            nn.Linear(9,32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,64),\n",
    "            nn.ReLU(),\n",
    "            # nn.Linear(64,128),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(128,32),\n",
    "            # nn.ReLU(),\n",
    "            nn.Linear(64,10),\n",
    "            )\n",
    "    def forward(self,inputs):\n",
    "        # print(inputs.shape)\n",
    "        # inputs=inputs.unsqueeze(1)\n",
    "        val_logits=self.linear_relu_val(inputs)\n",
    "        val_logits=nn.functional.softmax(val_logits,dim=1)\n",
    "        rem_logits=self.linear_relu_rem(inputs)\n",
    "        rem_logits=nn.functional.softmax(rem_logits,dim=1)\n",
    "        return val_logits,rem_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "# random_seed = 1\n",
    "# torch.manual_seed(random_seed)\n",
    "n_epochs = 300\n",
    "models = MLP().to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.requires_grad_(True)\n",
    "optimizer=torch.optim.Adam(models.parameters(), lr=learning_rate)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1],  Loss: 3.8149, value accuracy:0.6496,remoteness accuracy:0.5527\n",
      "Epoch [2],  Loss: 3.7603, value accuracy:0.6809,remoteness accuracy:0.5570\n",
      "Epoch [3],  Loss: 3.7407, value accuracy:0.6957,remoteness accuracy:0.5641\n",
      "Epoch [4],  Loss: 3.7220, value accuracy:0.7071,remoteness accuracy:0.5762\n",
      "Epoch [5],  Loss: 3.7123, value accuracy:0.7158,remoteness accuracy:0.5778\n",
      "Epoch [6],  Loss: 3.7060, value accuracy:0.7235,remoteness accuracy:0.5807\n",
      "Epoch [7],  Loss: 3.6921, value accuracy:0.7379,remoteness accuracy:0.5828\n",
      "Epoch [8],  Loss: 3.6833, value accuracy:0.7479,remoteness accuracy:0.5823\n",
      "Epoch [9],  Loss: 3.6740, value accuracy:0.7541,remoteness accuracy:0.5828\n",
      "Epoch [10],  Loss: 3.6654, value accuracy:0.7591,remoteness accuracy:0.5867\n",
      "Epoch [11],  Loss: 3.6570, value accuracy:0.7692,remoteness accuracy:0.5887\n",
      "Epoch [12],  Loss: 3.6516, value accuracy:0.7733,remoteness accuracy:0.5874\n",
      "Epoch [13],  Loss: 3.6438, value accuracy:0.7851,remoteness accuracy:0.5899\n",
      "Epoch [14],  Loss: 3.6387, value accuracy:0.7847,remoteness accuracy:0.5892\n",
      "Epoch [15],  Loss: 3.6349, value accuracy:0.7915,remoteness accuracy:0.5910\n",
      "Epoch [16],  Loss: 3.6297, value accuracy:0.7922,remoteness accuracy:0.5903\n",
      "Epoch [17],  Loss: 3.6271, value accuracy:0.7968,remoteness accuracy:0.5935\n",
      "Epoch [18],  Loss: 3.6204, value accuracy:0.8029,remoteness accuracy:0.5928\n",
      "Epoch [19],  Loss: 3.6152, value accuracy:0.8059,remoteness accuracy:0.5956\n",
      "Epoch [20],  Loss: 3.6099, value accuracy:0.8093,remoteness accuracy:0.5981\n",
      "Epoch [21],  Loss: 3.6064, value accuracy:0.8089,remoteness accuracy:0.5990\n",
      "Epoch [22],  Loss: 3.5986, value accuracy:0.8164,remoteness accuracy:0.6033\n",
      "Epoch [23],  Loss: 3.5981, value accuracy:0.8159,remoteness accuracy:0.6036\n",
      "Epoch [24],  Loss: 3.5956, value accuracy:0.8168,remoteness accuracy:0.6029\n",
      "Epoch [25],  Loss: 3.5900, value accuracy:0.8219,remoteness accuracy:0.6061\n",
      "Epoch [26],  Loss: 3.5892, value accuracy:0.8209,remoteness accuracy:0.6033\n",
      "Epoch [27],  Loss: 3.5872, value accuracy:0.8221,remoteness accuracy:0.6058\n",
      "Epoch [28],  Loss: 3.5803, value accuracy:0.8280,remoteness accuracy:0.6090\n",
      "Epoch [29],  Loss: 3.5789, value accuracy:0.8282,remoteness accuracy:0.6095\n",
      "Epoch [30],  Loss: 3.5757, value accuracy:0.8344,remoteness accuracy:0.6090\n",
      "Epoch [31],  Loss: 3.5747, value accuracy:0.8319,remoteness accuracy:0.6083\n",
      "Epoch [32],  Loss: 3.5702, value accuracy:0.8371,remoteness accuracy:0.6104\n",
      "Epoch [33],  Loss: 3.5700, value accuracy:0.8355,remoteness accuracy:0.6111\n",
      "Epoch [34],  Loss: 3.5673, value accuracy:0.8360,remoteness accuracy:0.6104\n",
      "Epoch [35],  Loss: 3.5663, value accuracy:0.8415,remoteness accuracy:0.6106\n",
      "Epoch [36],  Loss: 3.5629, value accuracy:0.8433,remoteness accuracy:0.6125\n",
      "Epoch [37],  Loss: 3.5625, value accuracy:0.8428,remoteness accuracy:0.6120\n",
      "Epoch [38],  Loss: 3.5620, value accuracy:0.8417,remoteness accuracy:0.6115\n",
      "Epoch [39],  Loss: 3.5570, value accuracy:0.8469,remoteness accuracy:0.6138\n",
      "Epoch [40],  Loss: 3.5557, value accuracy:0.8467,remoteness accuracy:0.6129\n",
      "Epoch [41],  Loss: 3.5560, value accuracy:0.8506,remoteness accuracy:0.6118\n",
      "Epoch [42],  Loss: 3.5546, value accuracy:0.8517,remoteness accuracy:0.6129\n",
      "Epoch [43],  Loss: 3.5516, value accuracy:0.8517,remoteness accuracy:0.6131\n",
      "Epoch [44],  Loss: 3.5514, value accuracy:0.8558,remoteness accuracy:0.6131\n",
      "Epoch [45],  Loss: 3.5510, value accuracy:0.8538,remoteness accuracy:0.6143\n",
      "Epoch [46],  Loss: 3.5499, value accuracy:0.8529,remoteness accuracy:0.6129\n",
      "Epoch [47],  Loss: 3.5456, value accuracy:0.8604,remoteness accuracy:0.6131\n",
      "Epoch [48],  Loss: 3.5463, value accuracy:0.8586,remoteness accuracy:0.6138\n",
      "Epoch [49],  Loss: 3.5450, value accuracy:0.8583,remoteness accuracy:0.6156\n",
      "Epoch [50],  Loss: 3.5465, value accuracy:0.8554,remoteness accuracy:0.6131\n",
      "Epoch [51],  Loss: 3.5414, value accuracy:0.8581,remoteness accuracy:0.6168\n",
      "Epoch [52],  Loss: 3.5440, value accuracy:0.8552,remoteness accuracy:0.6161\n",
      "Epoch [53],  Loss: 3.5396, value accuracy:0.8606,remoteness accuracy:0.6177\n",
      "Epoch [54],  Loss: 3.5401, value accuracy:0.8572,remoteness accuracy:0.6168\n",
      "Epoch [55],  Loss: 3.5432, value accuracy:0.8574,remoteness accuracy:0.6147\n",
      "Epoch [56],  Loss: 3.5346, value accuracy:0.8675,remoteness accuracy:0.6166\n",
      "Epoch [57],  Loss: 3.5369, value accuracy:0.8652,remoteness accuracy:0.6163\n",
      "Epoch [58],  Loss: 3.5364, value accuracy:0.8627,remoteness accuracy:0.6161\n",
      "Epoch [59],  Loss: 3.5330, value accuracy:0.8645,remoteness accuracy:0.6186\n",
      "Epoch [60],  Loss: 3.5315, value accuracy:0.8670,remoteness accuracy:0.6193\n",
      "Epoch [61],  Loss: 3.5289, value accuracy:0.8691,remoteness accuracy:0.6195\n",
      "Epoch [62],  Loss: 3.5293, value accuracy:0.8666,remoteness accuracy:0.6216\n",
      "Epoch [63],  Loss: 3.5273, value accuracy:0.8668,remoteness accuracy:0.6214\n",
      "Epoch [64],  Loss: 3.5297, value accuracy:0.8659,remoteness accuracy:0.6207\n",
      "Epoch [65],  Loss: 3.5245, value accuracy:0.8723,remoteness accuracy:0.6211\n",
      "Epoch [66],  Loss: 3.5254, value accuracy:0.8709,remoteness accuracy:0.6227\n",
      "Epoch [67],  Loss: 3.5236, value accuracy:0.8732,remoteness accuracy:0.6209\n",
      "Epoch [68],  Loss: 3.5245, value accuracy:0.8695,remoteness accuracy:0.6223\n",
      "Epoch [69],  Loss: 3.5203, value accuracy:0.8739,remoteness accuracy:0.6243\n",
      "Epoch [70],  Loss: 3.5222, value accuracy:0.8764,remoteness accuracy:0.6211\n",
      "Epoch [71],  Loss: 3.5238, value accuracy:0.8704,remoteness accuracy:0.6220\n",
      "Epoch [72],  Loss: 3.5211, value accuracy:0.8745,remoteness accuracy:0.6243\n",
      "Epoch [73],  Loss: 3.5149, value accuracy:0.8764,remoteness accuracy:0.6245\n",
      "Epoch [74],  Loss: 3.5187, value accuracy:0.8741,remoteness accuracy:0.6243\n",
      "Epoch [75],  Loss: 3.5141, value accuracy:0.8777,remoteness accuracy:0.6250\n",
      "Epoch [76],  Loss: 3.5137, value accuracy:0.8784,remoteness accuracy:0.6252\n",
      "Epoch [77],  Loss: 3.5119, value accuracy:0.8791,remoteness accuracy:0.6261\n",
      "Epoch [78],  Loss: 3.5120, value accuracy:0.8825,remoteness accuracy:0.6255\n",
      "Epoch [79],  Loss: 3.5180, value accuracy:0.8780,remoteness accuracy:0.6223\n",
      "Epoch [80],  Loss: 3.5158, value accuracy:0.8764,remoteness accuracy:0.6252\n",
      "Epoch [81],  Loss: 3.5133, value accuracy:0.8805,remoteness accuracy:0.6225\n",
      "Epoch [82],  Loss: 3.5125, value accuracy:0.8759,remoteness accuracy:0.6271\n",
      "Epoch [83],  Loss: 3.5075, value accuracy:0.8821,remoteness accuracy:0.6275\n",
      "Epoch [84],  Loss: 3.5121, value accuracy:0.8800,remoteness accuracy:0.6241\n",
      "Epoch [85],  Loss: 3.5076, value accuracy:0.8832,remoteness accuracy:0.6264\n",
      "Epoch [86],  Loss: 3.5095, value accuracy:0.8780,remoteness accuracy:0.6271\n",
      "Epoch [87],  Loss: 3.5093, value accuracy:0.8818,remoteness accuracy:0.6275\n",
      "Epoch [88],  Loss: 3.5078, value accuracy:0.8805,remoteness accuracy:0.6268\n",
      "Epoch [89],  Loss: 3.5054, value accuracy:0.8832,remoteness accuracy:0.6282\n",
      "Epoch [90],  Loss: 3.5052, value accuracy:0.8828,remoteness accuracy:0.6296\n",
      "Epoch [91],  Loss: 3.5008, value accuracy:0.8901,remoteness accuracy:0.6280\n",
      "Epoch [92],  Loss: 3.5015, value accuracy:0.8875,remoteness accuracy:0.6280\n",
      "Epoch [93],  Loss: 3.4992, value accuracy:0.8882,remoteness accuracy:0.6302\n",
      "Epoch [94],  Loss: 3.4971, value accuracy:0.8912,remoteness accuracy:0.6298\n",
      "Epoch [95],  Loss: 3.5000, value accuracy:0.8859,remoteness accuracy:0.6307\n",
      "Epoch [96],  Loss: 3.4986, value accuracy:0.8875,remoteness accuracy:0.6312\n",
      "Epoch [97],  Loss: 3.4976, value accuracy:0.8848,remoteness accuracy:0.6339\n",
      "Epoch [98],  Loss: 3.4957, value accuracy:0.8898,remoteness accuracy:0.6318\n",
      "Epoch [99],  Loss: 3.5005, value accuracy:0.8834,remoteness accuracy:0.6312\n",
      "Epoch [100],  Loss: 3.4979, value accuracy:0.8859,remoteness accuracy:0.6325\n",
      "Epoch [101],  Loss: 3.4954, value accuracy:0.8887,remoteness accuracy:0.6341\n",
      "Epoch [102],  Loss: 3.4939, value accuracy:0.8917,remoteness accuracy:0.6316\n",
      "Epoch [103],  Loss: 3.4933, value accuracy:0.8919,remoteness accuracy:0.6334\n",
      "Epoch [104],  Loss: 3.4933, value accuracy:0.8912,remoteness accuracy:0.6346\n",
      "Epoch [105],  Loss: 3.4899, value accuracy:0.8921,remoteness accuracy:0.6350\n",
      "Epoch [106],  Loss: 3.4895, value accuracy:0.8946,remoteness accuracy:0.6334\n",
      "Epoch [107],  Loss: 3.4901, value accuracy:0.8932,remoteness accuracy:0.6346\n",
      "Epoch [108],  Loss: 3.4896, value accuracy:0.8917,remoteness accuracy:0.6359\n",
      "Epoch [109],  Loss: 3.4891, value accuracy:0.8912,remoteness accuracy:0.6359\n",
      "Epoch [110],  Loss: 3.4913, value accuracy:0.8905,remoteness accuracy:0.6359\n",
      "Epoch [111],  Loss: 3.4896, value accuracy:0.8912,remoteness accuracy:0.6359\n",
      "Epoch [112],  Loss: 3.4886, value accuracy:0.8946,remoteness accuracy:0.6350\n",
      "Epoch [113],  Loss: 3.4867, value accuracy:0.8958,remoteness accuracy:0.6359\n",
      "Epoch [114],  Loss: 3.4840, value accuracy:0.8967,remoteness accuracy:0.6355\n",
      "Epoch [115],  Loss: 3.4838, value accuracy:0.8958,remoteness accuracy:0.6375\n",
      "Epoch [116],  Loss: 3.4881, value accuracy:0.8914,remoteness accuracy:0.6364\n",
      "Epoch [117],  Loss: 3.4857, value accuracy:0.8953,remoteness accuracy:0.6378\n",
      "Epoch [118],  Loss: 3.4838, value accuracy:0.8930,remoteness accuracy:0.6387\n",
      "Epoch [119],  Loss: 3.4823, value accuracy:0.8980,remoteness accuracy:0.6375\n",
      "Epoch [120],  Loss: 3.4824, value accuracy:0.8996,remoteness accuracy:0.6375\n",
      "Epoch [121],  Loss: 3.4849, value accuracy:0.8971,remoteness accuracy:0.6357\n",
      "Epoch [122],  Loss: 3.4843, value accuracy:0.8962,remoteness accuracy:0.6369\n",
      "Epoch [123],  Loss: 3.4873, value accuracy:0.8930,remoteness accuracy:0.6371\n",
      "Epoch [124],  Loss: 3.4809, value accuracy:0.8999,remoteness accuracy:0.6366\n",
      "Epoch [125],  Loss: 3.4802, value accuracy:0.9001,remoteness accuracy:0.6380\n",
      "Epoch [126],  Loss: 3.4813, value accuracy:0.8974,remoteness accuracy:0.6382\n",
      "Epoch [127],  Loss: 3.4816, value accuracy:0.8992,remoteness accuracy:0.6359\n",
      "Epoch [128],  Loss: 3.4826, value accuracy:0.8955,remoteness accuracy:0.6387\n",
      "Epoch [129],  Loss: 3.4815, value accuracy:0.8996,remoteness accuracy:0.6378\n",
      "Epoch [130],  Loss: 3.4781, value accuracy:0.8990,remoteness accuracy:0.6396\n",
      "Epoch [131],  Loss: 3.4800, value accuracy:0.8983,remoteness accuracy:0.6389\n",
      "Epoch [132],  Loss: 3.4793, value accuracy:0.8992,remoteness accuracy:0.6396\n",
      "Epoch [133],  Loss: 3.4798, value accuracy:0.8971,remoteness accuracy:0.6382\n",
      "Epoch [134],  Loss: 3.4756, value accuracy:0.9005,remoteness accuracy:0.6403\n",
      "Epoch [135],  Loss: 3.4782, value accuracy:0.9028,remoteness accuracy:0.6369\n",
      "Epoch [136],  Loss: 3.4764, value accuracy:0.9015,remoteness accuracy:0.6396\n",
      "Epoch [137],  Loss: 3.4760, value accuracy:0.9019,remoteness accuracy:0.6382\n",
      "Epoch [138],  Loss: 3.4742, value accuracy:0.9024,remoteness accuracy:0.6403\n",
      "Epoch [139],  Loss: 3.4754, value accuracy:0.9010,remoteness accuracy:0.6410\n",
      "Epoch [140],  Loss: 3.4750, value accuracy:0.9010,remoteness accuracy:0.6385\n",
      "Epoch [141],  Loss: 3.4741, value accuracy:0.9040,remoteness accuracy:0.6391\n",
      "Epoch [142],  Loss: 3.4742, value accuracy:0.9026,remoteness accuracy:0.6407\n",
      "Epoch [143],  Loss: 3.4789, value accuracy:0.8985,remoteness accuracy:0.6385\n",
      "Epoch [144],  Loss: 3.4753, value accuracy:0.8994,remoteness accuracy:0.6407\n",
      "Epoch [145],  Loss: 3.4753, value accuracy:0.9024,remoteness accuracy:0.6391\n",
      "Epoch [146],  Loss: 3.4728, value accuracy:0.9010,remoteness accuracy:0.6407\n",
      "Epoch [147],  Loss: 3.4723, value accuracy:0.9037,remoteness accuracy:0.6414\n",
      "Epoch [148],  Loss: 3.4690, value accuracy:0.9074,remoteness accuracy:0.6407\n",
      "Epoch [149],  Loss: 3.4739, value accuracy:0.8996,remoteness accuracy:0.6419\n",
      "Epoch [150],  Loss: 3.4698, value accuracy:0.9074,remoteness accuracy:0.6412\n",
      "Epoch [151],  Loss: 3.4714, value accuracy:0.9047,remoteness accuracy:0.6412\n",
      "Epoch [152],  Loss: 3.4681, value accuracy:0.9058,remoteness accuracy:0.6426\n",
      "Epoch [153],  Loss: 3.4736, value accuracy:0.9026,remoteness accuracy:0.6396\n",
      "Epoch [154],  Loss: 3.4687, value accuracy:0.9074,remoteness accuracy:0.6412\n",
      "Epoch [155],  Loss: 3.4682, value accuracy:0.9076,remoteness accuracy:0.6417\n",
      "Epoch [156],  Loss: 3.4654, value accuracy:0.9078,remoteness accuracy:0.6430\n",
      "Epoch [157],  Loss: 3.4659, value accuracy:0.9062,remoteness accuracy:0.6439\n",
      "Epoch [158],  Loss: 3.4651, value accuracy:0.9074,remoteness accuracy:0.6442\n",
      "Epoch [159],  Loss: 3.4660, value accuracy:0.9067,remoteness accuracy:0.6444\n",
      "Epoch [160],  Loss: 3.4653, value accuracy:0.9092,remoteness accuracy:0.6428\n",
      "Epoch [161],  Loss: 3.4640, value accuracy:0.9088,remoteness accuracy:0.6439\n",
      "Epoch [162],  Loss: 3.4679, value accuracy:0.9049,remoteness accuracy:0.6435\n",
      "Epoch [163],  Loss: 3.4612, value accuracy:0.9122,remoteness accuracy:0.6430\n",
      "Epoch [164],  Loss: 3.4654, value accuracy:0.9067,remoteness accuracy:0.6423\n",
      "Epoch [165],  Loss: 3.4640, value accuracy:0.9081,remoteness accuracy:0.6426\n",
      "Epoch [166],  Loss: 3.4629, value accuracy:0.9094,remoteness accuracy:0.6451\n",
      "Epoch [167],  Loss: 3.4630, value accuracy:0.9092,remoteness accuracy:0.6444\n",
      "Epoch [168],  Loss: 3.4650, value accuracy:0.9090,remoteness accuracy:0.6407\n",
      "Epoch [169],  Loss: 3.4597, value accuracy:0.9110,remoteness accuracy:0.6455\n",
      "Epoch [170],  Loss: 3.4605, value accuracy:0.9138,remoteness accuracy:0.6430\n",
      "Epoch [171],  Loss: 3.4648, value accuracy:0.9074,remoteness accuracy:0.6444\n",
      "Epoch [172],  Loss: 3.4582, value accuracy:0.9145,remoteness accuracy:0.6439\n",
      "Epoch [173],  Loss: 3.4650, value accuracy:0.9060,remoteness accuracy:0.6446\n",
      "Epoch [174],  Loss: 3.4603, value accuracy:0.9124,remoteness accuracy:0.6453\n",
      "Epoch [175],  Loss: 3.4601, value accuracy:0.9104,remoteness accuracy:0.6451\n",
      "Epoch [176],  Loss: 3.4602, value accuracy:0.9122,remoteness accuracy:0.6446\n",
      "Epoch [177],  Loss: 3.4600, value accuracy:0.9126,remoteness accuracy:0.6437\n",
      "Epoch [178],  Loss: 3.4601, value accuracy:0.9083,remoteness accuracy:0.6458\n",
      "Epoch [179],  Loss: 3.4614, value accuracy:0.9126,remoteness accuracy:0.6426\n",
      "Epoch [180],  Loss: 3.4574, value accuracy:0.9126,remoteness accuracy:0.6462\n",
      "Epoch [181],  Loss: 3.4559, value accuracy:0.9151,remoteness accuracy:0.6464\n",
      "Epoch [182],  Loss: 3.4595, value accuracy:0.9113,remoteness accuracy:0.6462\n",
      "Epoch [183],  Loss: 3.4581, value accuracy:0.9147,remoteness accuracy:0.6428\n",
      "Epoch [184],  Loss: 3.4572, value accuracy:0.9145,remoteness accuracy:0.6460\n",
      "Epoch [185],  Loss: 3.4566, value accuracy:0.9149,remoteness accuracy:0.6448\n",
      "Epoch [186],  Loss: 3.4589, value accuracy:0.9110,remoteness accuracy:0.6455\n",
      "Epoch [187],  Loss: 3.4574, value accuracy:0.9131,remoteness accuracy:0.6460\n",
      "Epoch [188],  Loss: 3.4575, value accuracy:0.9147,remoteness accuracy:0.6448\n",
      "Epoch [189],  Loss: 3.4582, value accuracy:0.9117,remoteness accuracy:0.6462\n",
      "Epoch [190],  Loss: 3.4549, value accuracy:0.9149,remoteness accuracy:0.6464\n",
      "Epoch [191],  Loss: 3.4602, value accuracy:0.9078,remoteness accuracy:0.6453\n",
      "Epoch [192],  Loss: 3.4561, value accuracy:0.9158,remoteness accuracy:0.6451\n",
      "Epoch [193],  Loss: 3.4583, value accuracy:0.9142,remoteness accuracy:0.6439\n",
      "Epoch [194],  Loss: 3.4610, value accuracy:0.9088,remoteness accuracy:0.6453\n",
      "Epoch [195],  Loss: 3.4588, value accuracy:0.9135,remoteness accuracy:0.6439\n",
      "Epoch [196],  Loss: 3.4562, value accuracy:0.9154,remoteness accuracy:0.6446\n",
      "Epoch [197],  Loss: 3.4546, value accuracy:0.9138,remoteness accuracy:0.6467\n",
      "Epoch [198],  Loss: 3.4574, value accuracy:0.9140,remoteness accuracy:0.6458\n",
      "Epoch [199],  Loss: 3.4546, value accuracy:0.9158,remoteness accuracy:0.6448\n",
      "Epoch [200],  Loss: 3.4543, value accuracy:0.9149,remoteness accuracy:0.6469\n",
      "Epoch [201],  Loss: 3.4531, value accuracy:0.9156,remoteness accuracy:0.6464\n",
      "Epoch [202],  Loss: 3.4525, value accuracy:0.9197,remoteness accuracy:0.6451\n",
      "Epoch [203],  Loss: 3.4561, value accuracy:0.9145,remoteness accuracy:0.6453\n",
      "Epoch [204],  Loss: 3.4537, value accuracy:0.9158,remoteness accuracy:0.6467\n",
      "Epoch [205],  Loss: 3.4538, value accuracy:0.9151,remoteness accuracy:0.6469\n",
      "Epoch [206],  Loss: 3.4573, value accuracy:0.9170,remoteness accuracy:0.6426\n",
      "Epoch [207],  Loss: 3.4534, value accuracy:0.9170,remoteness accuracy:0.6451\n",
      "Epoch [208],  Loss: 3.4510, value accuracy:0.9165,remoteness accuracy:0.6469\n",
      "Epoch [209],  Loss: 3.4528, value accuracy:0.9177,remoteness accuracy:0.6460\n",
      "Epoch [210],  Loss: 3.4533, value accuracy:0.9161,remoteness accuracy:0.6464\n",
      "Epoch [211],  Loss: 3.4520, value accuracy:0.9179,remoteness accuracy:0.6462\n",
      "Epoch [212],  Loss: 3.4537, value accuracy:0.9181,remoteness accuracy:0.6442\n",
      "Epoch [213],  Loss: 3.4532, value accuracy:0.9161,remoteness accuracy:0.6464\n",
      "Epoch [214],  Loss: 3.4522, value accuracy:0.9179,remoteness accuracy:0.6455\n",
      "Epoch [215],  Loss: 3.4501, value accuracy:0.9167,remoteness accuracy:0.6471\n",
      "Epoch [216],  Loss: 3.4501, value accuracy:0.9193,remoteness accuracy:0.6471\n",
      "Epoch [217],  Loss: 3.4558, value accuracy:0.9147,remoteness accuracy:0.6439\n",
      "Epoch [218],  Loss: 3.4532, value accuracy:0.9179,remoteness accuracy:0.6446\n",
      "Epoch [219],  Loss: 3.4508, value accuracy:0.9179,remoteness accuracy:0.6462\n",
      "Epoch [220],  Loss: 3.4524, value accuracy:0.9167,remoteness accuracy:0.6460\n",
      "Epoch [221],  Loss: 3.4538, value accuracy:0.9163,remoteness accuracy:0.6453\n",
      "Epoch [222],  Loss: 3.4516, value accuracy:0.9193,remoteness accuracy:0.6448\n",
      "Epoch [223],  Loss: 3.4564, value accuracy:0.9126,remoteness accuracy:0.6462\n",
      "Epoch [224],  Loss: 3.4519, value accuracy:0.9181,remoteness accuracy:0.6460\n",
      "Epoch [225],  Loss: 3.4511, value accuracy:0.9188,remoteness accuracy:0.6460\n",
      "Epoch [226],  Loss: 3.4497, value accuracy:0.9190,remoteness accuracy:0.6469\n",
      "Epoch [227],  Loss: 3.4514, value accuracy:0.9179,remoteness accuracy:0.6464\n",
      "Epoch [228],  Loss: 3.4503, value accuracy:0.9188,remoteness accuracy:0.6462\n",
      "Epoch [229],  Loss: 3.4487, value accuracy:0.9208,remoteness accuracy:0.6462\n",
      "Epoch [230],  Loss: 3.4525, value accuracy:0.9163,remoteness accuracy:0.6471\n",
      "Epoch [231],  Loss: 3.4541, value accuracy:0.9129,remoteness accuracy:0.6471\n",
      "Epoch [232],  Loss: 3.4452, value accuracy:0.9240,remoteness accuracy:0.6474\n",
      "Epoch [233],  Loss: 3.4491, value accuracy:0.9229,remoteness accuracy:0.6435\n",
      "Epoch [234],  Loss: 3.4508, value accuracy:0.9179,remoteness accuracy:0.6462\n",
      "Epoch [235],  Loss: 3.4502, value accuracy:0.9195,remoteness accuracy:0.6464\n",
      "Epoch [236],  Loss: 3.4490, value accuracy:0.9193,remoteness accuracy:0.6464\n",
      "Epoch [237],  Loss: 3.4508, value accuracy:0.9149,remoteness accuracy:0.6471\n",
      "Epoch [238],  Loss: 3.4499, value accuracy:0.9204,remoteness accuracy:0.6448\n",
      "Epoch [239],  Loss: 3.4524, value accuracy:0.9149,remoteness accuracy:0.6474\n",
      "Epoch [240],  Loss: 3.4472, value accuracy:0.9213,remoteness accuracy:0.6467\n",
      "Epoch [241],  Loss: 3.4509, value accuracy:0.9174,remoteness accuracy:0.6469\n",
      "Epoch [242],  Loss: 3.4500, value accuracy:0.9170,remoteness accuracy:0.6474\n",
      "Epoch [243],  Loss: 3.4493, value accuracy:0.9222,remoteness accuracy:0.6451\n",
      "Epoch [244],  Loss: 3.4496, value accuracy:0.9188,remoteness accuracy:0.6469\n",
      "Epoch [245],  Loss: 3.4504, value accuracy:0.9172,remoteness accuracy:0.6471\n",
      "Epoch [246],  Loss: 3.4478, value accuracy:0.9204,remoteness accuracy:0.6471\n",
      "Epoch [247],  Loss: 3.4500, value accuracy:0.9195,remoteness accuracy:0.6469\n",
      "Epoch [248],  Loss: 3.4435, value accuracy:0.9250,remoteness accuracy:0.6464\n",
      "Epoch [249],  Loss: 3.4487, value accuracy:0.9204,remoteness accuracy:0.6460\n",
      "Epoch [250],  Loss: 3.4521, value accuracy:0.9167,remoteness accuracy:0.6462\n",
      "Epoch [251],  Loss: 3.4480, value accuracy:0.9206,remoteness accuracy:0.6462\n",
      "Epoch [252],  Loss: 3.4466, value accuracy:0.9227,remoteness accuracy:0.6462\n",
      "Epoch [253],  Loss: 3.4472, value accuracy:0.9211,remoteness accuracy:0.6467\n",
      "Epoch [254],  Loss: 3.4446, value accuracy:0.9227,remoteness accuracy:0.6471\n",
      "Epoch [255],  Loss: 3.4457, value accuracy:0.9231,remoteness accuracy:0.6467\n",
      "Epoch [256],  Loss: 3.4468, value accuracy:0.9224,remoteness accuracy:0.6464\n",
      "Epoch [257],  Loss: 3.4449, value accuracy:0.9236,remoteness accuracy:0.6469\n",
      "Epoch [258],  Loss: 3.4445, value accuracy:0.9240,remoteness accuracy:0.6474\n",
      "Epoch [259],  Loss: 3.4429, value accuracy:0.9254,remoteness accuracy:0.6474\n",
      "Epoch [260],  Loss: 3.4462, value accuracy:0.9227,remoteness accuracy:0.6467\n",
      "Epoch [261],  Loss: 3.4473, value accuracy:0.9231,remoteness accuracy:0.6458\n",
      "Epoch [262],  Loss: 3.4480, value accuracy:0.9220,remoteness accuracy:0.6453\n",
      "Epoch [263],  Loss: 3.4479, value accuracy:0.9224,remoteness accuracy:0.6444\n",
      "Epoch [264],  Loss: 3.4449, value accuracy:0.9229,remoteness accuracy:0.6474\n",
      "Epoch [265],  Loss: 3.4435, value accuracy:0.9238,remoteness accuracy:0.6483\n",
      "Epoch [266],  Loss: 3.4430, value accuracy:0.9222,remoteness accuracy:0.6496\n",
      "Epoch [267],  Loss: 3.4350, value accuracy:0.9247,remoteness accuracy:0.6565\n",
      "Epoch [268],  Loss: 3.4338, value accuracy:0.9245,remoteness accuracy:0.6581\n",
      "Epoch [269],  Loss: 3.4304, value accuracy:0.9266,remoteness accuracy:0.6585\n",
      "Epoch [270],  Loss: 3.4311, value accuracy:0.9236,remoteness accuracy:0.6613\n",
      "Epoch [271],  Loss: 3.4279, value accuracy:0.9259,remoteness accuracy:0.6631\n",
      "Epoch [272],  Loss: 3.4295, value accuracy:0.9254,remoteness accuracy:0.6631\n",
      "Epoch [273],  Loss: 3.4289, value accuracy:0.9254,remoteness accuracy:0.6629\n",
      "Epoch [274],  Loss: 3.4263, value accuracy:0.9252,remoteness accuracy:0.6642\n",
      "Epoch [275],  Loss: 3.4232, value accuracy:0.9272,remoteness accuracy:0.6665\n",
      "Epoch [276],  Loss: 3.4254, value accuracy:0.9252,remoteness accuracy:0.6647\n",
      "Epoch [277],  Loss: 3.4251, value accuracy:0.9234,remoteness accuracy:0.6686\n",
      "Epoch [278],  Loss: 3.4237, value accuracy:0.9243,remoteness accuracy:0.6686\n",
      "Epoch [279],  Loss: 3.4214, value accuracy:0.9279,remoteness accuracy:0.6677\n",
      "Epoch [280],  Loss: 3.4195, value accuracy:0.9277,remoteness accuracy:0.6695\n",
      "Epoch [281],  Loss: 3.4174, value accuracy:0.9300,remoteness accuracy:0.6713\n",
      "Epoch [282],  Loss: 3.4233, value accuracy:0.9229,remoteness accuracy:0.6686\n",
      "Epoch [283],  Loss: 3.4210, value accuracy:0.9243,remoteness accuracy:0.6722\n",
      "Epoch [284],  Loss: 3.4168, value accuracy:0.9277,remoteness accuracy:0.6713\n",
      "Epoch [285],  Loss: 3.4198, value accuracy:0.9250,remoteness accuracy:0.6715\n",
      "Epoch [286],  Loss: 3.4172, value accuracy:0.9263,remoteness accuracy:0.6727\n",
      "Epoch [287],  Loss: 3.4156, value accuracy:0.9297,remoteness accuracy:0.6724\n",
      "Epoch [288],  Loss: 3.4183, value accuracy:0.9243,remoteness accuracy:0.6727\n",
      "Epoch [289],  Loss: 3.4194, value accuracy:0.9245,remoteness accuracy:0.6724\n",
      "Epoch [290],  Loss: 3.4186, value accuracy:0.9240,remoteness accuracy:0.6736\n",
      "Epoch [291],  Loss: 3.4135, value accuracy:0.9291,remoteness accuracy:0.6736\n",
      "Epoch [292],  Loss: 3.4114, value accuracy:0.9313,remoteness accuracy:0.6750\n",
      "Epoch [293],  Loss: 3.4143, value accuracy:0.9277,remoteness accuracy:0.6759\n",
      "Epoch [294],  Loss: 3.4198, value accuracy:0.9215,remoteness accuracy:0.6754\n",
      "Epoch [295],  Loss: 3.4170, value accuracy:0.9270,remoteness accuracy:0.6736\n",
      "Epoch [296],  Loss: 3.4110, value accuracy:0.9302,remoteness accuracy:0.6754\n",
      "Epoch [297],  Loss: 3.4156, value accuracy:0.9270,remoteness accuracy:0.6743\n",
      "Epoch [298],  Loss: 3.4116, value accuracy:0.9291,remoteness accuracy:0.6756\n",
      "Epoch [299],  Loss: 3.4129, value accuracy:0.9284,remoteness accuracy:0.6754\n",
      "Epoch [300],  Loss: 3.4128, value accuracy:0.9277,remoteness accuracy:0.6754\n"
     ]
    }
   ],
   "source": [
    "models.requires_grad_(True)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    models.train(True)\n",
    "    train_loss=0\n",
    "    val_acc=0\n",
    "    rem_acc=0\n",
    "    for data, val_target,rem_target in dataset_loader:\n",
    "        optimizer.zero_grad()\n",
    "        val_outputs,rem_outputs = models(data)\n",
    "        val_predicted = torch.argmax(val_outputs, dim=1)\n",
    "        rem_predicted = torch.argmax(rem_outputs, dim=1)\n",
    "        v_correct = (val_predicted == val_target).sum()\n",
    "        r_correct = (rem_predicted == rem_target).sum()\n",
    "        # print(rem_outputs.size(),rem_target.size(),rem_outputs)\n",
    "        rem_outputs=rem_outputs.squeeze(1)\n",
    "        loss_val = loss_func(val_outputs, val_target)\n",
    "        loss_rem = loss_func(rem_outputs, rem_target)\n",
    "        # print(val_predicted,val_target,rem_outputs,rem_target)\n",
    "        loss=loss_val+loss_rem\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "       \n",
    "        train_loss+=loss\n",
    "        val_acc+=v_correct\n",
    "        rem_acc+=r_correct\n",
    "    train_loss = train_loss/(len(train_loader))\n",
    "    val_acc=val_acc/(len(train_loader)*batch_size)\n",
    "    rem_acc=rem_acc/(len(train_loader)*batch_size)\n",
    "    # print('Epoch [{}], Accuracy:{:.4f}, Loss: {:.4f}'\n",
    "    #             .format(epoch + 1, acc,train_loss.item()))\n",
    "    print('Epoch [{}],  Loss: {:.4f}, value accuracy:{:.4f},remoteness accuracy:{:.4f}'\n",
    "                .format(epoch + 1, train_loss.item(),val_acc,rem_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_val): Sequential(\n",
       "    (0): Linear(in_features=9, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=32, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=3, bias=True)\n",
       "  )\n",
       "  (linear_relu_rem): Sequential(\n",
       "    (0): Linear(in_features=9, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=32, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(models.state_dict(), './mlp.pt')\n",
    "models.load_state_dict(torch.load('./mlp.pt'))\n",
    "models.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "exception_table=[]\n",
    "for data, val_target,rem_target in dataset_loader:\n",
    "    val_outputs,rem_outputs = models(data)\n",
    "    val_predicted = torch.argmax(val_outputs, dim=1)\n",
    "    rem_predicted = torch.argmax(rem_outputs, dim=1)\n",
    "    # print()\n",
    "    ar_data=np.array(data,dtype=int)\n",
    "    hash_positions=[hash_table[tuple(i)] for i in ar_data]\n",
    "    \n",
    "    delta_val=val_predicted-val_target\n",
    "    delta_rem=rem_predicted-rem_target\n",
    "    for idx,i in enumerate(delta_val):\n",
    "        if i!=0 or delta_rem[idx]!=0:\n",
    "            exception_table.append([hash_positions[idx],ar_data[idx],int(i),int(delta_rem[idx])])\n",
    "    # exception_table.append([val_outputs,rem_outputs,val_target,rem_target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2819"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(exception_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"exception_delta.csv\"\n",
    "\n",
    "import csv\n",
    "with open(csv_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    for row in exception_table:\n",
    "        writer.writerow(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
